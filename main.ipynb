{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_model(\n",
      "  (sa1): PointNetSetAbstractionMsg(\n",
      "    (conv_blocks): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): Conv2d(12, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): Conv2d(12, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (bn_blocks): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0-1): 2 x BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0-1): 2 x BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sa2): PointNetSetAbstractionMsg(\n",
      "    (conv_blocks): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): Conv2d(99, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (bn_blocks): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0-1): 2 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sa3): PointNetSetAbstractionMsg(\n",
      "    (conv_blocks): ModuleList(\n",
      "      (0-1): 2 x ModuleList(\n",
      "        (0): Conv2d(259, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(128, 196, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): Conv2d(196, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (bn_blocks): ModuleList(\n",
      "      (0-1): 2 x ModuleList(\n",
      "        (0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (sa4): PointNetSetAbstractionMsg(\n",
      "    (conv_blocks): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): Conv2d(515, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (2): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (bn_blocks): ModuleList(\n",
      "      (0): ModuleList(\n",
      "        (0-1): 2 x BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): ModuleList(\n",
      "        (0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fp4): PointNetFeaturePropagation(\n",
      "    (mlp_convs): ModuleList(\n",
      "      (0): Conv1d(1536, 256, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (mlp_bns): ModuleList(\n",
      "      (0-1): 2 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (fp3): PointNetFeaturePropagation(\n",
      "    (mlp_convs): ModuleList(\n",
      "      (0): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (mlp_bns): ModuleList(\n",
      "      (0-1): 2 x BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (fp2): PointNetFeaturePropagation(\n",
      "    (mlp_convs): ModuleList(\n",
      "      (0): Conv1d(352, 256, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(256, 128, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (mlp_bns): ModuleList(\n",
      "      (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (fp1): PointNetFeaturePropagation(\n",
      "    (mlp_convs): ModuleList(\n",
      "      (0-2): 3 x Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (mlp_bns): ModuleList(\n",
      "      (0-2): 3 x BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop1): Dropout(p=0.5, inplace=False)\n",
      "  (conv2): Conv1d(128, 13, kernel_size=(1,), stride=(1,))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from models.pointnet2_sem_seg_msg import get_model\n",
    "\n",
    "model = get_model(13)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils.S3DISDataLoader import S3DISDataset\n",
    "import torch\n",
    "def foo():\n",
    "    root = 'data/stanford_indoor3d/'\n",
    "    NUM_CLASSES = 13\n",
    "    NUM_POINT = 1024\n",
    "    BATCH_SIZE = 16\n",
    "    TRAIN_DATASET = S3DISDataset(split='train', data_root=root, num_point=NUM_POINT, test_area='5', block_size=1.0, sample_rate=1.0, transform=None)\n",
    "    loader = torch.utils.data.DataLoader(TRAIN_DATASET)\n",
    "    return loader\n",
    "loader = foo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1024, 9]), torch.Size([1, 1024]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx = next(iter(loader))\n",
    "(xx[0].size(), xx[1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string '/home/g111056119/Documents/7111056119/Pointnet_Pointnet2_pytorch/data/modelnet40_normal_resampled/a to float64 at row 0, column 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '/home/g111056119/Documents/7111056119/Pointnet_Pointnet2_pytorch/data/modelnet40_normal_resampled/airplane/airplane_0271.txt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/g111056119/Documents/7111056119/Pointnet_Pointnet2_pytorch/main.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2252545832303730227d/home/g111056119/Documents/7111056119/Pointnet_Pointnet2_pytorch/main.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m xx[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m]\n",
      "File \u001b[0;32m~/Documents/7111056119/Pointnet_Pointnet2_pytorch/data_utils/MAML_ModelNetDataLoader40.py:61\u001b[0m, in \u001b[0;36mMAMLModelNetDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     59\u001b[0m start \u001b[39m=\u001b[39m index \u001b[39m*\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m     60\u001b[0m end \u001b[39m=\u001b[39m (index \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m---> 61\u001b[0m cat_points \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39;49mloadtxt(x[start:end], delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat32) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcat_dir_files_1000]\n\u001b[1;32m     62\u001b[0m cat_points \u001b[39m=\u001b[39m [x[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnpoints] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m cat_points]\n\u001b[1;32m     63\u001b[0m cat_points \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39m*\u001b[39mcat_points)\n",
      "File \u001b[0;32m~/Documents/7111056119/Pointnet_Pointnet2_pytorch/data_utils/MAML_ModelNetDataLoader40.py:61\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     59\u001b[0m start \u001b[39m=\u001b[39m index \u001b[39m*\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m     60\u001b[0m end \u001b[39m=\u001b[39m (index \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m---> 61\u001b[0m cat_points \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39;49mloadtxt(x[start:end], delimiter\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcat_dir_files_1000]\n\u001b[1;32m     62\u001b[0m cat_points \u001b[39m=\u001b[39m [x[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnpoints] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m cat_points]\n\u001b[1;32m     63\u001b[0m cat_points \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39m*\u001b[39mcat_points)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_practice/lib/python3.11/site-packages/numpy/lib/npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delimiter, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1371\u001b[0m     delimiter \u001b[39m=\u001b[39m delimiter\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1373\u001b[0m arr \u001b[39m=\u001b[39m _read(fname, dtype\u001b[39m=\u001b[39;49mdtype, comment\u001b[39m=\u001b[39;49mcomment, delimiter\u001b[39m=\u001b[39;49mdelimiter,\n\u001b[1;32m   1374\u001b[0m             converters\u001b[39m=\u001b[39;49mconverters, skiplines\u001b[39m=\u001b[39;49mskiprows, usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[1;32m   1375\u001b[0m             unpack\u001b[39m=\u001b[39;49munpack, ndmin\u001b[39m=\u001b[39;49mndmin, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1376\u001b[0m             max_rows\u001b[39m=\u001b[39;49mmax_rows, quote\u001b[39m=\u001b[39;49mquotechar)\n\u001b[1;32m   1378\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m~/anaconda3/envs/torch_practice/lib/python3.11/site-packages/numpy/lib/npyio.py:1016\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     data \u001b[39m=\u001b[39m _preprocess_comments(data, comments, encoding)\n\u001b[1;32m   1015\u001b[0m \u001b[39mif\u001b[39;00m read_dtype_via_object_chunks \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1016\u001b[0m     arr \u001b[39m=\u001b[39m _load_from_filelike(\n\u001b[1;32m   1017\u001b[0m         data, delimiter\u001b[39m=\u001b[39;49mdelimiter, comment\u001b[39m=\u001b[39;49mcomment, quote\u001b[39m=\u001b[39;49mquote,\n\u001b[1;32m   1018\u001b[0m         imaginary_unit\u001b[39m=\u001b[39;49mimaginary_unit,\n\u001b[1;32m   1019\u001b[0m         usecols\u001b[39m=\u001b[39;49musecols, skiplines\u001b[39m=\u001b[39;49mskiplines, max_rows\u001b[39m=\u001b[39;49mmax_rows,\n\u001b[1;32m   1020\u001b[0m         converters\u001b[39m=\u001b[39;49mconverters, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1021\u001b[0m         encoding\u001b[39m=\u001b[39;49mencoding, filelike\u001b[39m=\u001b[39;49mfilelike,\n\u001b[1;32m   1022\u001b[0m         byte_converters\u001b[39m=\u001b[39;49mbyte_converters)\n\u001b[1;32m   1024\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1025\u001b[0m     \u001b[39m# This branch reads the file into chunks of object arrays and then\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[39m# casts them to the desired actual dtype.  This ensures correct\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m     \u001b[39m# string-length and datetime-unit discovery (like `arr.astype()`).\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m     \u001b[39m# Due to chunking, certain error reports are less clear, currently.\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m     \u001b[39mif\u001b[39;00m filelike:\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string '/home/g111056119/Documents/7111056119/Pointnet_Pointnet2_pytorch/data/modelnet40_normal_resampled/a to float64 at row 0, column 1."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
